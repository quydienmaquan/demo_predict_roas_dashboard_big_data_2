{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors pyngrok joblib scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXSLpuYTfFPJ",
        "outputId": "67316a4c-9f94-4f6d-c30b-b59ff6334aa0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "from flask import Flask, jsonify, request\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "FPdLD_nyfKQ2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- C·∫§U H√åNH ---\n",
        "MODEL_PATH = '/content/roas_model.pkl'\n",
        "DATA_PATH = '/content/Ppc_campaign_performance_data.xlsx'\n",
        "SCALER_PATH = '/content/data_scaler.pkl'  # L∆∞u scaler ƒë·ªÉ d√πng cho prediction\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWnLuS2JiCHH",
        "outputId": "9aae84cf-00aa-4023-a0b6-fecede0014eb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<flask_cors.extension.CORS at 0x7c238cdd1580>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_save_model():\n",
        "    print(\"ƒêang kh·ªüi t·∫°o v√† hu·∫•n luy·ªán l·∫°i model Scikit-Learn...\")\n",
        "\n",
        "    if not os.path.exists(DATA_PATH):\n",
        "        print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file {DATA_PATH}. H√£y upload l·∫°i file Excel!\")\n",
        "        return None\n",
        "\n",
        "    # ƒê·ªçc d·ªØ li·ªáu\n",
        "    df = pd.read_excel(DATA_PATH)\n",
        "\n",
        "    # Ti·ªÅn x·ª≠ l√Ω c∆° b·∫£n\n",
        "    df = df.fillna(df.mean(numeric_only=True))\n",
        "    if df.duplicated().sum() > 0:\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "    # X√°c ƒë·ªãnh bi·∫øn X, y\n",
        "    if 'ROAS' not in df.columns:\n",
        "        print(\"‚ùå L·ªói: File d·ªØ li·ªáu kh√¥ng c√≥ c·ªôt 'ROAS'\")\n",
        "        return None\n",
        "\n",
        "    X = df.drop(columns=['ROAS'])\n",
        "    y = df['ROAS']\n",
        "\n",
        "    # X√°c ƒë·ªãnh lo·∫°i c·ªôt\n",
        "    numeric_features = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    print(f\"üìä Numeric features: {numeric_features}\")\n",
        "    print(f\"üìä Categorical features: {categorical_features}\")\n",
        "\n",
        "    # T·∫°o Pipeline\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    model_pipeline = Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('rf', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "    # Chia t·∫≠p train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "    print(\"‚úÖ Hu·∫•n luy·ªán xong!\")\n",
        "\n",
        "    # L∆∞u model\n",
        "    joblib.dump(model_pipeline, MODEL_PATH)\n",
        "    print(f\"‚úÖ ƒê√£ l∆∞u model m·ªõi t·∫°i: {MODEL_PATH}\")\n",
        "\n",
        "    # L∆∞u feature names ƒë·ªÉ d√πng sau\n",
        "    joblib.dump({\n",
        "        'numeric_features': numeric_features,\n",
        "        'categorical_features': categorical_features\n",
        "    }, SCALER_PATH)\n",
        "\n",
        "    return model_pipeline"
      ],
      "metadata": {
        "id": "k1vClqGNiGgS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try:\n",
        "#    global_model = train_and_save_model()\n",
        "#except Exception as e:\n",
        "#    print(f\"‚ùå L·ªói nghi√™m tr·ªçng khi train model: {e}\")"
      ],
      "metadata": {
        "id": "betDQ1nPiIne"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.before_request\n",
        "def log_request_info():\n",
        "    if request.path != '/':\n",
        "        print(f\"üîç Dashboard ƒëang g·ªçi: [{request.method}] {request.path}\")\n",
        "\n",
        "def get_replay_data():\n",
        "    if not os.path.exists(DATA_PATH) or not os.path.exists(MODEL_PATH):\n",
        "        return None, \"Thi·∫øu file Data ho·∫∑c Model. Vui l√≤ng ki·ªÉm tra l·∫°i log.\"\n",
        "\n",
        "    try:\n",
        "        # Load l·∫°i model t·ª´ file v·ª´a l∆∞u\n",
        "        model = joblib.load(MODEL_PATH)\n",
        "        df = pd.read_excel(DATA_PATH)\n",
        "\n",
        "        # Clean Data & IQR Filter\n",
        "        df = df.fillna(df.mean(numeric_only=True))\n",
        "        if df.duplicated().sum() > 0:\n",
        "            df = df.drop_duplicates()\n",
        "\n",
        "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "        for col in numeric_cols:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower = Q1 - 1.5 * IQR\n",
        "            upper = Q3 + 1.5 * IQR\n",
        "            df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
        "\n",
        "        # T√°ch t·∫≠p Test\n",
        "        X = df.drop(columns=['ROAS'], errors='ignore')\n",
        "        y = df['ROAS']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # D·ª± b√°o\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Metrics\n",
        "        metrics = {\n",
        "            \"r2_score\": round(r2_score(y_test, y_pred), 4),\n",
        "            \"rmse\": round(np.sqrt(mean_squared_error(y_test, y_pred)), 2),\n",
        "            \"mae\": round(mean_absolute_error(y_test, y_pred), 2)\n",
        "        }\n",
        "\n",
        "        # T·∫°o DataFrame k·∫øt qu·∫£\n",
        "        df_res = X_test.copy()\n",
        "        df_res['Actual'] = y_test.values\n",
        "        df_res['Predicted'] = y_pred\n",
        "        df_res['Residuals'] = y_test.values - y_pred\n",
        "\n",
        "        # Alias c·ªôt cho Frontend\n",
        "        df_res['actual'] = df_res['Actual']\n",
        "        df_res['predicted'] = df_res['Predicted']\n",
        "        df_res['ROAS'] = df_res['Actual']\n",
        "        df_res['Predicted_ROAS'] = df_res['Predicted']\n",
        "\n",
        "        if 'Date' in df_res.columns:\n",
        "            df_res['Date'] = df_res['Date'].astype(str)\n",
        "            df_res = df_res.sort_values('Date')\n",
        "\n",
        "        # Feature Importance\n",
        "        num_df = df_res.select_dtypes(include=[np.number])\n",
        "        if 'Actual' in num_df.columns:\n",
        "            corr = num_df.corr()['Actual'].abs().sort_values(ascending=False)\n",
        "            feats = [{\"feature\": k, \"importance\": round(v, 3)} for k, v in corr.items()\n",
        "                     if k not in ['Actual', 'Predicted', 'Residuals', 'actual', 'predicted', 'ROAS', 'Predicted_ROAS']]\n",
        "        else:\n",
        "            feats = []\n",
        "\n",
        "        # Distribution Data\n",
        "        hist_values, bin_edges = np.histogram(y_test, bins=10)\n",
        "        distribution_data = {\n",
        "            \"labels\": [f\"{int(bin_edges[i])}-{int(bin_edges[i+1])}\" for i in range(len(hist_values))],\n",
        "            \"values\": hist_values.tolist()\n",
        "        }\n",
        "\n",
        "        # ========== FIX #1: Bi·ªÉu ƒë·ªì So S√°nh Th·ª±c T·∫ø vs D·ª± B√°o ==========\n",
        "        comparison_data = []\n",
        "        for idx in range(min(50, len(df_res))):  # L·∫•y top 50 samples\n",
        "            comparison_data.append({\n",
        "                \"index\": idx,\n",
        "                \"actual\": float(df_res.iloc[idx]['Actual']),\n",
        "                \"predicted\": float(df_res.iloc[idx]['Predicted']),\n",
        "                \"error\": abs(float(df_res.iloc[idx]['Actual']) - float(df_res.iloc[idx]['Predicted']))\n",
        "            })\n",
        "\n",
        "        # Clean NaN\n",
        "        df_res = df_res.where(pd.notnull(df_res), None)\n",
        "\n",
        "        return {\n",
        "            \"data\": df_res.head(1000).to_dict(orient='records'),\n",
        "            \"metrics\": metrics,\n",
        "            \"feature_importance\": feats[:10],\n",
        "            \"visualizations\": {\n",
        "                \"roas_distribution\": distribution_data,\n",
        "                \"scatter_data\": df_res[['Actual', 'Predicted']].head(200).to_dict(orient='records'),\n",
        "                \"comparison_chart\": comparison_data  # ‚úÖ Th√™m d·ªØ li·ªáu so s√°nh\n",
        "            }\n",
        "        }, None\n",
        "    except Exception as e:\n",
        "        return None, f\"L·ªói logic get_replay_data: {str(e)}\""
      ],
      "metadata": {
        "id": "5t895YrdiN4u"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ROUTES ---\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "    return \"<h1>‚úÖ System Active - API Running</h1>\"\n",
        "\n",
        "@app.route('/load-data', methods=['GET', 'POST'])\n",
        "def load_data():\n",
        "    try:\n",
        "        data, err = get_replay_data()\n",
        "        if err:\n",
        "            return jsonify({\"status\": \"error\", \"message\": err}), 500\n",
        "\n",
        "        response = {\n",
        "            \"status\": \"success\",\n",
        "            \"model_info\": \"Random Forest (Retrained with Full Pipeline)\",\n",
        "        }\n",
        "        response.update(data)\n",
        "        return jsonify(response)\n",
        "    except Exception as e:\n",
        "        return jsonify({\"status\": \"error\", \"message\": str(e)}), 500\n"
      ],
      "metadata": {
        "id": "l-muZpS0iRYb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== FIX #2: Endpoint D·ª± B√°o Ho·∫°t ƒê·ªông ƒê√∫ng ==========\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    \"\"\"\n",
        "    INPUT JSON:\n",
        "    {\n",
        "        \"Budget\": 1000,\n",
        "        \"Clicks\": 500,\n",
        "        \"Campaign_ID\": 1,\n",
        "        \"Date\": \"2025-01-15\",\n",
        "        \"Spend\": 950,\n",
        "        \"Impressions\": 5000,\n",
        "        ... (c√°c c·ªôt kh√°c n·∫øu c√≥)\n",
        "    }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = joblib.load(MODEL_PATH)\n",
        "        feature_info = joblib.load(SCALER_PATH)\n",
        "\n",
        "        data = request.json\n",
        "        print(f\"üì• Input nh·∫≠n ƒë∆∞·ª£c: {data}\")\n",
        "\n",
        "        # L·∫•y d·ªØ li·ªáu g·ªëc ƒë·ªÉ bi·∫øt c·∫•u tr√∫c ƒë√∫ng\n",
        "        df_original = pd.read_excel(DATA_PATH)\n",
        "        X_original = df_original.drop(columns=['ROAS'], errors='ignore')\n",
        "\n",
        "        # T·∫°o DataFrame t·ª´ input\n",
        "        input_df = pd.DataFrame([data])\n",
        "\n",
        "        # ƒê·∫£m b·∫£o t·∫•t c·∫£ c·ªôt c√≥ m·∫∑t (n·∫øu kh√¥ng c√≥ th√¨ ƒëi·ªÅn 0)\n",
        "        for col in X_original.columns:\n",
        "            if col not in input_df.columns:\n",
        "                # N·∫øu l√† numeric, ƒëi·ªÅn 0; n·∫øu l√† categorical, ƒëi·ªÅn 'Unknown'\n",
        "                if col in feature_info['numeric_features']:\n",
        "                    input_df[col] = 0\n",
        "                else:\n",
        "                    input_df[col] = 'Unknown'\n",
        "\n",
        "        # Ch·ªâ gi·ªØ nh·ªØng c·ªôt c√≥ trong X_original\n",
        "        input_df = input_df[X_original.columns]\n",
        "\n",
        "        print(f\"DataFrame sau x·ª≠ l√Ω: \\n{input_df}\")\n",
        "        print(f\"Shape: {input_df.shape}\")\n",
        "\n",
        "        # D·ª± b√°o\n",
        "        pred = model.predict(input_df)[0]\n",
        "        result = round(float(pred), 2)\n",
        "\n",
        "        # Quy·∫øt ƒë·ªãnh\n",
        "        decision = \"N√äN CH·∫†Y üöÄ\" if result > 3 else \"KH√îNG N√äN CH·∫†Y üõë\"\n",
        "        decision_color = \"green\" if result > 3 else \"red\"\n",
        "\n",
        "        print(f\"‚úÖ D·ª± b√°o ROAS: {result} - {decision}\")\n",
        "\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"predicted_roas\": result,\n",
        "            \"decision\": decision,\n",
        "            \"decision_color\": decision_color,\n",
        "            \"input_received\": data\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå L·ªói predict: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\n",
        "            \"status\": \"error\",\n",
        "            \"message\": str(e),\n",
        "            \"details\": \"Ki·ªÉm tra console ƒë·ªÉ xem chi ti·∫øt\"\n",
        "        }), 400\n"
      ],
      "metadata": {
        "id": "anf-XSK7iSUc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== ENDPOINT TH√äM: L·∫•y danh s√°ch c·ªôt c·∫ßn input ==========\n",
        "@app.route('/get-input-schema', methods=['GET'])\n",
        "def get_input_schema():\n",
        "    \"\"\"Tr·∫£ v·ªÅ schema input m√† frontend c·∫ßn\"\"\"\n",
        "    try:\n",
        "        feature_info = joblib.load(SCALER_PATH)\n",
        "        df_original = pd.read_excel(DATA_PATH)\n",
        "        X_original = df_original.drop(columns=['ROAS'], errors='ignore')\n",
        "\n",
        "        schema = {\n",
        "            \"numeric_features\": feature_info['numeric_features'],\n",
        "            \"categorical_features\": feature_info['categorical_features'],\n",
        "            \"all_columns\": X_original.columns.tolist()\n",
        "        }\n",
        "\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"schema\": schema\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            \"status\": \"error\",\n",
        "            \"message\": str(e)\n",
        "        }), 400\n"
      ],
      "metadata": {
        "id": "VkZtK3uWibxB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RUN SERVER ---\n",
        "if __name__ == \"__main__\":\n",
        "    ngrok.set_auth_token(\"379rdueKynm53Bks6IFd6tg2QNo_6ue7ZARJqC9zviNWy1uVT\")\n",
        "    ngrok.kill()\n",
        "    public_url = ngrok.connect(5000).public_url\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"LINK API M·ªöI: {public_url}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMWLjVqzhYK5",
        "outputId": "b07012c4-2433-4ae0-f049-a37b112c7d60"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "LINK API M·ªöI: https://ronna-fleshiest-luana.ngrok-free.dev\n",
            "============================================================\n",
            "\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Dec/2025 16:42:38] \"OPTIONS /load-data HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Dashboard ƒëang g·ªçi: [OPTIONS] /load-data\n",
            "üîç Dashboard ƒëang g·ªçi: [GET] /load-data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Dec/2025 16:42:39] \"GET /load-data HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Dec/2025 16:43:22] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Dashboard ƒëang g·ªçi: [OPTIONS] /predict\n",
            "üîç Dashboard ƒëang g·ªçi: [POST] /predict\n",
            "üì• Input nh·∫≠n ƒë∆∞·ª£c: {'Budget': 2453, 'Clicks': 23423, 'CTR': 1, 'CPC': 2, 'Conversions': 32, 'CPA': 23, 'Conversion_Rate': 1, 'Duration': 23, 'Revenue': 2342, 'Spend': 23452, 'Impressions': 23234, 'Platform': 'Google', 'Content_Type': 'Video', 'Target_Age': '18-24', 'Target_Gender': 'Male', 'Region': 'Africa'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Dec/2025 16:43:22] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame sau x·ª≠ l√Ω: \n",
            "  Campaign_ID  Budget  Clicks  CTR  CPC  Conversions  CPA  Conversion_Rate  \\\n",
            "0     Unknown    2453   23423    1    2           32   23                1   \n",
            "\n",
            "   Duration Platform Content_Type Target_Age Target_Gender  Region  Revenue  \\\n",
            "0        23   Google        Video      18-24          Male  Africa     2342   \n",
            "\n",
            "   Spend     Date  Impressions  \n",
            "0  23452  Unknown        23234  \n",
            "Shape: (1, 18)\n",
            "‚úÖ D·ª± b√°o ROAS: 1.99 - KH√îNG N√äN CH·∫†Y üõë\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [26/Dec/2025 16:43:42] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}